<p align="center"><img src="https://imgur.com/QKXXaZ6.png" width=400></p>

# üíª JOM Parser  ![a](https://img.shields.io/badge/C%2B%2B-20-blue) ![a](https://img.shields.io/badge/repo%20size-6mb-orange)

> Proyecto 1 con tema de "Organizaci√≥n de archivos" para Base de Datos II (CS2042) - Utec, con Prof. Heider Sanchez.

## Objetivo
El objetivo de nuestro proyecto es implementar y comparar dos estructuras de organizaci√≥n de archivos para lograr una recuperaci√≥n y manipulaci√≥n de datos eficiente. Espec√≠ficamente, compararemos el rendimiento de las siguientes estructuras:
- [AVL File](https://en.wikipedia.org/wiki/AVL_tree)
- [Extendible-Hashing](https://en.wikipedia.org/wiki/Extendible_hashing)

Para evaluar las estructuras implementaremos las siguientes funciones:
- **Search**: dada una llave, retornaremos los registros respectivos.
- **Range search**: Dado un rango de llaves, retornar todos los registros cuyas llaves se encuentren dentro del rango.
- **Add**: a√±adir un nuevo registro al archivo.
- **Remove**: eliminar un registro del archivo.

## üìä Datos
Usaremos dos datasets de Kaggle para simular nuestro parser SQL: [NBA](https://www.kaggle.com/datasets/ethanchen44/nba-playoff-predictions) y [Tornados](https://www.kaggle.com/datasets/danbraswell/us-tornado-dataset-1950-2021). Estos datasets contienen predicciones para los playoffs de la NBA y datos sobre tornados en EE.UU. Respectivamente, usaremos una estructura de organizaci√≥n de archivo diferente para cada dataset y haremos un archivo que contenga los √≠ndices para cada registro de manera que facilite los accesos. Ambos datasets fueron extra√≠dos de Kaggle y contienen alrededor de 3000 y 70000 registros, respectivamente.

## üìù Resultados esperados
Despu√©s de realizar una comparaci√≥n del rendimiento del AVL y el Extendible-Hashing en base a las funciones implementadas utilizando los dos datasets, mediremos las siguientes m√©tricas:

- ‚è≥ Tiempo de ejecuci√≥n: Tiempo requerido para ejecutar cada funci√≥n en cada estructura para cada dataset.
- üõ∞ Uso de memoria: Cantidad de memoria requerida para guardar cada archivo en cada estructura.

Es importante destacar que de antemano tenemos conocimiento sobre las fortalezas y debilidades de cada estructura. Los √°rboles AVL permiten b√∫squedas, b√∫squedas por rango e inserciones r√°pidas, pero su uso de memoria es alto. Por otro lado, el Extendible-Hashing utiliza menos memoria y soporta datasets grandes de manera eficiente, sin embargo, no soporta b√∫squedas por rango.

Una vez concluido el proyecto, los resultados obtenidos nos permitir√°n comprender mejor las ventajas y desventajas de cada estructura de organizaci√≥n de archivos y su idoneidad para diferentes tipos de conjuntos de datos y operaciones.

## T√©cnicas de indexaci√≥n
### AVL Tree
A diferencia del Sequential File y el ISAM, el AVL ofrece una mayor eficiencia en la b√∫squeda y manipulaci√≥n de registros individuales, lo que lo hace m√°s adecuado para aplicaciones en las que se necesitan b√∫squedas frecuentes y eficientes de registros. Para aplicaciones que requieren busquedas por rango de valores en la clave de indexacion tambien es bueno.

Sin embargo, el ISAM puede ser m√°s adecuado para aplicaciones con conjuntos de datos muy grandes debido a su capacidad para dividir los datos en m√∫ltiples bloques y distribuirlos en diferentes archivos. Adem√°s, el ISAM puede ser m√°s eficiente en t√©rminos de uso de memoria ya que no necesita almacenar la estructura completa del √°rbol como lo hace el AVL File.

### Extensible Hashing
Tanto el Extensible Hashing como el B+ Tree son estructuras de organizaci√≥n de archivos eficientes y muy utilizadas en la actualidad. 

En cuanto a la inserci√≥n de nuevos registros, ambas estructuras son muy eficientes, pero el Extensible Hashing tiene una ventaja en este aspecto ya que es m√°s f√°cil de balancear y manejar. En el B+ Tree, si se realiza una inserci√≥n que rompe la regla de balanceo del √°rbol, puede requerir una reorganizaci√≥n costosa y compleja. En otros tipos de extensible hashing, el B+ Tree es m√°s eficiente en la eliminaci√≥n de registros, ya que elimina los registros directamente de las hojas del √°rbol, mientras que en el Extensible Hashing se tiene que reorganizar las celdas libres. En este caso no es asi, lo hemos hecho de una manera para que las eliminaciones sean mas eficientes.

El B+ Tree es m√°s adecuado para trabajar con conjuntos de datos grandes y dispersos, mientras que el Extensible Hashing es m√°s adecuado para conjuntos de datos peque√±os y densos. Adem√°s, el B+ Tree es m√°s flexible y puede manejar una amplia gama de operaciones de b√∫squeda, como b√∫squeda por rango y b√∫squeda con m√∫ltiples claves, mientras que el Extensible Hashing solo puede manejar b√∫squedas por clave exacta.

En cuanto al uso de memoria, el Extensible Hashing es m√°s eficiente, ya que solo requiere espacio adicional para el directorio hash, mientras que el B+ Tree requiere espacio adicional para todos los nodos del √°rbol. Por lo tanto, el Extensible Hashing es una buena opci√≥n para conjuntos de datos que pueden crecer r√°pidamente, ya que puede expandirse din√°micamente sin requerir grandes cantidades de memoria adicional.

Para ser sinceros, a final de cuentas elegimos el hash para no codear el B+ üòåüëç honestidad ante todo.

## Documentaci√≥n Parser

üìù Insertar todos los registros de un csv a una tabla.  
```INSERT INTO table FROM file.csv```

üîé Buscar registros con la llave dentro de un rango.  
```SELECT * FROM table BETWEEN start end```

üîç Buscar registros con una llave especifica.  
```SELECT * FROM table EQUALS value```

üñç Borrar registros que tengan una llave especifica.  
```DELETE FROM table value```


## Configuraci√≥n
En el folder de "BDII-MINIMAL-PROJECT/datos", a√±ade un csv del cual se quiera extraer los datos. Despues simplemente corre el archivo:
- ./main.exe : Windows
- ./a.out : Mac OS

Y se ejecutara el archivo, despues unicamente queda realizar los queries, para copiar la base de datos en una estructura simplemente es hacer INSERT INTO tabla FROM archivo.csv. 

> Antes de hacer eso se debe crear un **struct** con los registros y sus campos para posteriormente en el ```main.cpp``` reemplazar el ```RegistroNBA``` que viene por defecto con el registro creado. Para cambiar el **fill factor** del extensible hashing simplemente cambie el const int que se encuentra en el hash.h y despues vuelva a compilar.  

Ejemplo: ```g++ -std=c++20 main.cpp```

## Resultados Obtenidos
<p align="center"><img src="https://imgur.com/TXwXGPF.png" width=400></p>
<p align="center"><img src="https://imgur.com/Kdd2A9g.png" width=400></p>
<p align="center"><img src="https://imgur.com/A8fAH1H.png" width=400></p>
<p align="center"><img src="https://imgur.com/ssntMRr.png" width=400></p>

Vemos que para las inserciones tanto el AVL como el Hash demoran mas tiempo. Sin embargo, el Hash demora mas. Nos preguntamos por que seria eso, dado que las complejidades teoricas decian que la insercion del hash es de O(1), y luego determinamos que el numero de buckets en linea seria de aproximadamente 50 con el numero de datos mas grande. Ademas la implementacion del hash realiza una busqueda (es decir realiza dos "pasadas" sobre el archivo: la busqueda y la insercion propiamente dicha) para determinar unicidad a difierencia del AVL, que simplemente inserta el valor dado que es un multimap. Podemos ver sin embargo que el hash es mas eficiente con menos datos, cuando sus buckets aun no estan llenos. Sobre el AVl vemos que su tiempo crece considerablemente mas lento, pero aun mustra una forma curva sugiriendo que su comportamiento por algun motivo no es del todo logarimico como se sabe de la teoria (es probable que se deba a las inserciones en las linked lists que conforman sus nodos).

El AVL como era esperado es muchisimo mas rapido en todas las busquedas por rango, y a pesar de los pocos puntos de datos pareciera asomar una complejidad logaritmica, aunque con lo rapido que es tambien podria ser la variacion de corrida a corrida.

De los tiempos de busqueda no podemos concluir mucho, pues ambos son relativamente bajos y estan sujetos a varianza de muestra a muestra. Sin embargo podemos ver una tendencia del AVL a desempe√±arse peor cuando hay menos datos en comparacion al hash. Nuevamente, esto debe ser por culpa de los encadenamientos si es que no se trata de la mencionada varianza de muestra a muestra.

## Video funcionamiento Extendible Hashing
Tras finalizar la clase, nos dimos cuenta que el error era que pusimos como max_index del extendible hashing 32 y al parecer eso genera problema no se por que, despues con un numero como 16 si funcionaba todo correctamente.
https://drive.google.com/drive/folders/1s8VDEkBeCJ9y53u2AWoeb6a0ySF9ZWo4?usp=share_link

